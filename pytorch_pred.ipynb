{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Readmission using Pytorch's Logistic Regression and DAN\n",
    "\n",
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from argparse import ArgumentParser\n",
    "from datetime import datetime\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from typing import Dict, List, Tuple, Type\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from scipy import sparse\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Logistic regression binary classification model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        \"\"\"\n",
    "        # Parameters\n",
    "        num_features : `int`, required.\n",
    "            Number of the features.\n",
    "        # Returns\n",
    "            `None`\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Hw-TODO: Add a linear layer to weight the features.\n",
    "        self.linear = nn.Linear(in_features=num_features, out_features=1, bias=True)\n",
    "\n",
    "    def forward(self, features):\n",
    "        \"\"\"\n",
    "        Returns the logits of the model given features. \n",
    "        Note that model predictions should be either 0 or 1 based on a threshold.\n",
    "        # Parameters\n",
    "        features : `torch.FloatTensor`, required.\n",
    "            The tensor of features with the shape (batch_size, num_of_features)\n",
    "        # Returns\n",
    "        probs : `torch.FloatTensor`, required.\n",
    "            The tensor of probabilities with the shape (batch_size, 1) or (batch_size,)\n",
    "        \"\"\"\n",
    "        # Hw-TODO: Use `self.linear` you created in `__init__`\n",
    "        #          and appropriate nonlinearity/activation-function to compute\n",
    "        #          and return the probabilities of belonging to a class in the logistic regression.\n",
    "        out = self.linear(features)\n",
    "        probs = torch.sigmoid(out)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassificationLModule(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # Save arguments to `hparams` attribute, see the doc [here](https://pytorch-lightning.readthedocs.io/en/latest/common/hyperparameters.html).\n",
    "        self.save_hyperparameters()\n",
    "        data_dir = Path(self.hparams.data_dir)\n",
    "        #self.hparams.vocab = json.load(\n",
    "        #    open(data_dir.joinpath(self.hparams.vocab_filename)))\n",
    "        #self.hparams.vocab_size = len(self.hparams.vocab)\n",
    "\n",
    "        self.model = self.get_model()\n",
    "        self.step_count = 0\n",
    "        self.accuracy = Accuracy()\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.model(*args, **kwargs)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input = self.batch2input(batch)\n",
    "        labels = self.batch2labels(batch)\n",
    "        probs = self(**input)\n",
    "        probs = probs.squeeze()\n",
    "        # Hw-TODO: Given probs in shape (batch_size,)\n",
    "        #          and labels of the same shape,\n",
    "        #          compute the binary cross entropy loss.\n",
    "        loss = nn.functional.binary_cross_entropy(probs, labels)\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_acc', self.accuracy(probs, labels.int()), prog_bar=True)\n",
    "        output_dict = {'loss': loss}\n",
    "        return output_dict\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input = self.batch2input(batch)\n",
    "        labels = self.batch2labels(batch)\n",
    "        probs = self(**input)\n",
    "        probs = probs.squeeze()\n",
    "\n",
    "        # Hw-TODO: Given probs in shape (batch_size,)\n",
    "        #          and labels of the same shape,\n",
    "        #          compute the binary cross entropy loss.\n",
    "        loss = nn.functional.binary_cross_entropy(probs, labels)\n",
    "\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', self.accuracy(probs, labels.int()))\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input = self.batch2input(batch)\n",
    "        labels = self.batch2labels(batch)\n",
    "        probs = self(**input)\n",
    "        probs = probs.squeeze()\n",
    "\n",
    "        # Hw-TODO: Given probs in shape (batch_size,)\n",
    "        #          and labels of the same shape,\n",
    "        #          compute the binary cross entropy loss.\n",
    "        loss = nn.functional.binary_cross_entropy(probs, labels)\n",
    "\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', self.accuracy(probs, labels.int()))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.hparams.optimizer == 'sgd':\n",
    "            optimizer = torch.optim.SGD(self.model.parameters(),\n",
    "                                        lr=self.hparams.learning_rate)\n",
    "        elif self.hparams.optimizer == 'adam':\n",
    "            optimizer = torch.optim.Adam(self.model.parameters(),\n",
    "                                         lr=self.hparams.learning_rate)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.get_dataloader('train', self.hparams.train_batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.get_dataloader('dev', self.hparams.eval_batch_size, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.get_dataloader('test', self.hparams.eval_batch_size, shuffle=False)\n",
    "\n",
    "    def get_model(self) -> nn.Module:\n",
    "        # To be overridden by inherited classes.\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def batch2input(self, batch: Tuple[torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        # To be overridden by inherited classes.\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def batch2labels(self, batch: Tuple[torch.Tensor]) -> torch.Tensor:\n",
    "        # To be overridden by inherited classes.\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_dataloader(self,\n",
    "                       split: str,\n",
    "                       batch_size: int,\n",
    "                       shuffle: bool = False) -> DataLoader:\n",
    "        # To be overridden by inherited classes.\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @classmethod\n",
    "    def add_model_specific_args(cls, parser: ArgumentParser) -> ArgumentParser:\n",
    "        \"\"\"\n",
    "        Add arguments to the parser and return the parser.\n",
    "        \"\"\"\n",
    "        # Required arguments:\n",
    "        parser.add_argument('--vocab_filename',\n",
    "                            default=None,\n",
    "                            type=str,\n",
    "                            required=False,  # changing to false since we're not using vocab\n",
    "                            help=\"File name of the feature.\")\n",
    "        # Optional arguments:\n",
    "        parser.add_argument('--optimizer',\n",
    "                            default='adam',\n",
    "                            type=str,\n",
    "                            help=\"The optimizer to use, such as sgd or adam.\")\n",
    "        parser.add_argument('--learning_rate',\n",
    "                            default=1e-3,\n",
    "                            type=float,\n",
    "                            help=\"The initial learning rate for training.\")\n",
    "        parser.add_argument('--max_epochs',\n",
    "                            default=10,\n",
    "                            type=int,\n",
    "                            help=\"The number of epochs to train your model.\")\n",
    "        parser.add_argument('--train_batch_size', default=32, type=int)\n",
    "        parser.add_argument('--eval_batch_size', default=32, type=int)\n",
    "        parser.add_argument('--seed',\n",
    "                            type=int,\n",
    "                            default=42,\n",
    "                            help=\"The random seed for initialization\")\n",
    "        parser.add_argument('--do_train',\n",
    "                            action=\"store_true\",\n",
    "                            default=True,\n",
    "                            help=\"Whether to run training.\")\n",
    "        parser.add_argument('--do_predict',\n",
    "                            action=\"store_true\",\n",
    "                            help=\"Whether to run predictions on the test set.\")\n",
    "        parser.add_argument('--data_dir',\n",
    "                            default=\"data\",\n",
    "                            type=str,\n",
    "                            help=\"The input data dir. Should contain the training files.\")\n",
    "        parser.add_argument('--output_dir',\n",
    "                            type=str,\n",
    "                            help=(\"The output directory where the model predictions \"\n",
    "                                  \"and checkpoints will be written.\"))\n",
    "        # NOTE: Set --gpus 0 or change the default value to 0 if not using GPUS.\n",
    "        # See this [link](https://pytorch-lightning.readthedocs.io/en/latest/accelerators/gpu.html) for usage of this argument.\n",
    "        parser.add_argument('--gpus',\n",
    "                            default=1,\n",
    "                            type=int,\n",
    "                            help=\"The number of GPUs allocated for this, 0 meaning none\")\n",
    "        parser.add_argument('--num_workers',\n",
    "                            default=8,\n",
    "                            type=int,\n",
    "                            help=\"Config `DataLoader` of pytorch\")\n",
    "        return parser\n",
    "\n",
    "\n",
    "def generic_train(args: argparse.Namespace,\n",
    "                  model_class: Type[pl.LightningModule]) -> Dict:\n",
    "    \"\"\"\n",
    "        Train (and optionally predict) and return dict results.\n",
    "        # Parameters\n",
    "        args : `argparse.Namespace`, required.\n",
    "            Configuration of the training and the model\n",
    "        model_class : `Type[pl.LightningModule]`, required.\n",
    "            Class of the model to be trained.\n",
    "        # Returns\n",
    "        A `dict` object containing the following keys and types.\n",
    "            trainer: `pl.Trainer`\n",
    "            model: `pl.LightningModule`\n",
    "            val_results_best: `list[dict]`\n",
    "                If `args.do_predict==True`\n",
    "            test_results_best: `list[dict]`\n",
    "                If `args.do_predict==True`\n",
    "            best_model_path: `Path`\n",
    "                Path to the checkpoint of the best model.\n",
    "        \"\"\"\n",
    "    pl.seed_everything(args.seed)\n",
    "\n",
    "    tensorboard_log_dir = Path(args.output_dir).joinpath('tensorboard_logs')\n",
    "    tensorboard_log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Tensorboard logger\n",
    "    tensorboard_logger = pl_loggers.TensorBoardLogger(\n",
    "        save_dir=tensorboard_log_dir,\n",
    "        version='version_' + datetime.now().strftime('%Y%m%d-%H%M%S'),\n",
    "        name='',\n",
    "        default_hp_metric=True)\n",
    "    # Checkpoint callback\n",
    "    checkpoint_dir = Path(args.output_dir).joinpath(tensorboard_logger.version,\n",
    "                                                    'checkpoints')\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=checkpoint_dir,\n",
    "                                                       filename='{epoch}-{val_acc:.2f}',\n",
    "                                                       monitor='val_acc',\n",
    "                                                       mode='max',\n",
    "                                                       save_top_k=1,\n",
    "                                                       verbose=True)\n",
    "\n",
    "    dict_args = vars(args)\n",
    "    model = model_class(**dict_args)\n",
    "    trainer = pl.Trainer.from_argparse_args(args,\n",
    "                                            logger=tensorboard_logger,\n",
    "                                            callbacks=[checkpoint_callback])\n",
    "\n",
    "    output_dict = {'trainer': trainer, 'model': model}\n",
    "\n",
    "    if args.do_train:\n",
    "        trainer.fit(model=model)\n",
    "        # Track model performance under differnt hparams settings in \"Hparams\" of TensorBoard\n",
    "        tensorboard_logger.log_hyperparams(\n",
    "            params=model.hparams,\n",
    "            metrics={'hp_metric': checkpoint_callback.best_model_score.item()})\n",
    "        tensorboard_logger.save()\n",
    "\n",
    "        # Save the best model to `best_model.ckpt`\n",
    "        best_model_path = checkpoint_dir.joinpath('best_model.ckpt')\n",
    "        logger.info(f\"Copy best model from {checkpoint_callback.best_model_path} \"\n",
    "                    f\"to {best_model_path}.\")\n",
    "        shutil.copy(checkpoint_callback.best_model_path, best_model_path)\n",
    "\n",
    "        output_dict.update({\n",
    "            'trainer': trainer,\n",
    "            'model': model,\n",
    "            'best_model_path': best_model_path\n",
    "        })\n",
    "\n",
    "    # Optionally, predict on test set.\n",
    "    if args.do_predict:\n",
    "        best_model_path = checkpoint_dir.joinpath('best_model.ckpt')\n",
    "        model = model.load_from_checkpoint(best_model_path)\n",
    "        #val_results_best = trainer.validate(model, verbose=True)\n",
    "        test_results_best = trainer.test(model, verbose=True)\n",
    "        #print(\"Validation accuracy on the best model: {: .4f}\".format(\n",
    "        #    val_results_best[0]['val_acc']))\n",
    "        print(\"Test       accuracy on the best model: {: .4f}\".format(\n",
    "            test_results_best[0]['test_acc']))\n",
    "        output_dict.update({\n",
    "        #    'val_results_best': val_results_best,\n",
    "            'test_results_best': test_results_best,\n",
    "        })\n",
    "\n",
    "    return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureBasedBinaryClassificationLModule(BinaryClassificationLModule):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def get_model(self) -> nn.Module:\n",
    "        return LogisticRegressionModel(num_features=512)\n",
    "\n",
    "    def batch2input(self, batch):\n",
    "        return {'features': batch[0]}\n",
    "\n",
    "    def batch2labels(self, batch):\n",
    "        return batch[1]\n",
    "\n",
    "    def get_dataloader(self,\n",
    "                       split: str,\n",
    "                       batch_size: int,\n",
    "                       shuffle: bool = False) -> DataLoader:\n",
    "        # NOTE: In order to use different features, change feature_name by\n",
    "        # passing `--feature_name <feature_name>` in the training loop in\n",
    "        # the cell below, or revise the code here for correct paths if needed.\n",
    "        data_dir = Path(self.hparams.data_dir)\n",
    "        features_filepath = data_dir.joinpath(\n",
    "            f\"{split}_{self.hparams.feature_name}_features.npz\")\n",
    "        labels_filepath = data_dir.joinpath(split + \"_labels.npz\")\n",
    "        features = sparse.load_npz(features_filepath).todense()\n",
    "        print('features shape:',features.shape)\n",
    "        #labels = np.load(labels_filepath, allow_pickle=True)[\"arr_0\"]\n",
    "        labels = np.asarray(sparse.load_npz(labels_filepath).todense()).ravel()\n",
    "        print('labels shape:',labels.shape)\n",
    "        dataset = torch.utils.data.TensorDataset(\n",
    "            torch.from_numpy(features).float(),\n",
    "            torch.from_numpy(labels).float())\n",
    "\n",
    "        logger.info(f\"Loading {split} features and labels \"\n",
    "                    f\"from {features_filepath} and {labels_filepath}\")\n",
    "        data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=shuffle,\n",
    "                                                  num_workers=self.hparams.num_workers)\n",
    "        return data_loader\n",
    "\n",
    "    @classmethod\n",
    "    def add_model_specific_args(cls, parser: ArgumentParser) -> ArgumentParser:\n",
    "        parser = super().add_model_specific_args(parser)\n",
    "        # Required arguments:\n",
    "        parser.add_argument('--feature_name',\n",
    "                            default=None,\n",
    "                            type=str,\n",
    "                            required=True,\n",
    "                            help=\"Name of the feature\")\n",
    "        # Optional arguments:\n",
    "        parser.add_argument('--task',\n",
    "                            default='featurebinarycls',\n",
    "                            type=str,\n",
    "                            help=\"Name of the task.\")\n",
    "        return parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.asarray(sparse.load_npz('./data/train_labels.npz').todense()).ravel()\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                    | Params\n",
      "-----------------------------------------------------\n",
      "0 | model    | LogisticRegressionModel | 513   \n",
      "1 | accuracy | Accuracy                | 0     \n",
      "-----------------------------------------------------\n",
      "513       Trainable params\n",
      "0         Non-trainable params\n",
      "513       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed arguments: Namespace(vocab_filename=None, optimizer='adam', learning_rate=0.001, max_epochs=2, train_batch_size=32, eval_batch_size=32, seed=42, do_train=True, do_predict=True, data_dir='data', output_dir='output/ftrlogistic', gpus=1, num_workers=8, feature_name='roberta_readmit', task='featurebinarycls')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a780290dea12461a9aa0b4a3eaf8c491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 14:37:32 - INFO - __main__ - Loading dev features and labels from data/dev_roberta_readmit_features.npz and data/dev_labels.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (58328, 512)\n",
      "labels shape: (58328,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "2022-03-14 14:37:34 - INFO - __main__ - Loading train features and labels from data/train_roberta_readmit_features.npz and data/train_labels.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (58328, 512)\n",
      "labels shape: (58328,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13992cf5f98944f9ab4318d2dc181228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb4ed2a6cc0468984eed6ad091a39b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 1822: val_acc reached 0.95729 (best 0.95729), saving model to \"/mnt/c/Users/natra/Documents/Education/UChicago/NLP/n2c2-track2-nlp-uchicago/output/ftrlogistic/version_20220314-143730/checkpoints/epoch=0-val_acc=0.96.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a34d9751fae49928632c06cbfe91ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 3645: val_acc was not in top 1\n",
      "2022-03-14 14:38:51 - INFO - __main__ - Copy best model from /mnt/c/Users/natra/Documents/Education/UChicago/NLP/n2c2-track2-nlp-uchicago/output/ftrlogistic/version_20220314-143730/checkpoints/epoch=0-val_acc=0.96.ckpt to output/ftrlogistic/version_20220314-143730/checkpoints/best_model.ckpt.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2022-03-14 14:38:53 - INFO - __main__ - Loading test features and labels from data/test_roberta_readmit_features.npz and data/test_labels.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (58328, 512)\n",
      "labels shape: (58328,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58fb94cd3e949ed8ded9ed3d6c2c1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.9572932124137878, 'test_loss': 4.270676136016846}\n",
      "--------------------------------------------------------------------------------\n",
      "Test       accuracy on the best model:  0.9573\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "                    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load hyperparameters\n",
    "parser = ArgumentParser()\n",
    "parser = FeatureBasedBinaryClassificationLModule.add_model_specific_args(parser)\n",
    "\n",
    "# NOTE: You should replace `unigram_binary` in the assignment statement of `args_str =...`\n",
    "# with whatever feature that you are experimented with.\n",
    "# You can also configure other options listed in the method of add_model_specific_args of\n",
    "# the pytorch-lightning model `FeatureBasedBinaryClassificationLModule`.\n",
    "args_str = (\"--feature_name roberta_readmit --max_epochs 5 \"\n",
    "            \"--output_dir output/ftrlogistic --optimizer adam --do_train --do_predict\")\n",
    "\n",
    "args = parser.parse_args(args_str.split())\n",
    "\n",
    "# If output_dir not provided, a folder is generated\n",
    "if args.output_dir is None:\n",
    "    args.output_dir = str(\n",
    "        Path('output').joinpath(\n",
    "            f\"{args.task}_{datetime.now().strftime('%Y%m%d-%H%M%S')}\"))\n",
    "Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Parsed arguments: {args}\")\n",
    "\n",
    "training_outout = generic_train(args=args,\n",
    "                                model_class=FeatureBasedBinaryClassificationLModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepAveragingNetworksModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 #vocab,\n",
    "                 vocab_size: int,\n",
    "                 word_embedding_size: int,\n",
    "                 hidden_size: int,\n",
    "                 num_intermediate_layers: int,\n",
    "                 dropout_rate: float,\n",
    "                 use_glove: bool = False):\n",
    "        \"\"\"\n",
    "        # Parameters\n",
    "        vocab : `dict[str, int]`, required.\n",
    "            A map from the word type to the index of the word.\n",
    "        vocab_size : `int`, required.\n",
    "            Size of the vocabulary.\n",
    "        word_embedding_size : `int`, required.\n",
    "            Size of word embeddings.\n",
    "        hidden_size : `int`, required.\n",
    "            Size of hidden layer or number of hidden units per layer.\n",
    "        num_intermediate_layers : `int`, required.\n",
    "            Number of intermediate layers, the arg takes 0 or greater integers.\n",
    "        dropout_rate : `float`, required.\n",
    "            Dropout rate.\n",
    "        use_glove : `bool`, optional.\n",
    "            Whether or not to use Glove embeddings instead of randomly initialized ones.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Return zero vector for input with padding_idx (0)\n",
    "        self.embedding = nn.Embedding(vocab_size, word_embedding_size, padding_idx=0)\n",
    "\n",
    "        # Hw-TODO: Add the intermediate layers, output layer, dropout layer,\n",
    "        #          and activation function according to DAN.\n",
    "        #          You may find [nn.Modulelist](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html)\n",
    "        #          useful to have multiple intermediate layers.\n",
    "        if num_intermediate_layers == 0:\n",
    "            self.hidden_layers = None\n",
    "            self.output_layer = nn.Linear(word_embedding_size, 1)\n",
    "        else:\n",
    "            self.hidden_layers = nn.ModuleList(\n",
    "                [nn.Linear(word_embedding_size, hidden_size)] + [\n",
    "                    nn.Linear(hidden_size, hidden_size)\n",
    "                    for _ in range(num_intermediate_layers - 1)\n",
    "                ])\n",
    "            self.output_layer = nn.Linear(hidden_size, 1)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, input_ids, lengths):\n",
    "        \"\"\"\n",
    "        # Parameters\n",
    "        input_ids : `torch.Tensor`, required.\n",
    "            Tensor of shape (batch_size, feature_length).\n",
    "            Each row is a datapoint represented by input words.\n",
    "        lengths: `torch.Tensor`, required.\n",
    "            Tensor of shape (batch_size, 1). Token length of input text.\n",
    "            Used to compute average word embeddings.\n",
    "        # Returns\n",
    "        probs : `torch.Tensor`\n",
    "            Tensor of shape (batch_size)\n",
    "        \"\"\"\n",
    "        print('input ids shape:',input_ids.shape)\n",
    "        out = self.embedding(input_ids)  # shape: (batch_sz, max_len, embedding_sz)\n",
    "\n",
    "        # Hw-TODO: Use the intermediate layers, output layer, dropout layer,\n",
    "        #          and activation function you created in __init__\n",
    "        #          and other appropriate non-linearity for the output layer\n",
    "        #          to compute the probabilies of a class, assign these probabilities\n",
    "        #          to a variable named \"probs\".\n",
    " \n",
    "        out = torch.sum(out, dim=1) / lengths  # shape: (batch_sz, embedding_sz)\n",
    "        if self.hidden_layers is not None:\n",
    "            for hidden_layer in self.hidden_layers:\n",
    "                out = hidden_layer(out)\n",
    "                out = self.activation(out)\n",
    "                out = self.dropout(out)\n",
    "        out = self.output_layer(out)\n",
    "        probs = torch.sigmoid(out)\n",
    "\n",
    "        return probs # you will define this variable in the preceding code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class SST2Dataset(Dataset):\n",
    "\n",
    "\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        #self.vocab = vocab\n",
    "        self.max_len = 512  # change when running full bioclinical bert\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        note = []\n",
    "        #label, text = int(self.data[index][0]), self.data[index][1]\n",
    "        #tokens = self.tokenizer.tokenize(text.lower())\n",
    "        # If word does not exist, give <unk> token id\n",
    "        #token_ids = [self.vocab.get(t, 1) for t in tokens]\n",
    "        length = self.max_len\n",
    "        features = sparse.load_npz(features_filepath).todense()\n",
    "        print('features shape:',features.shape)\n",
    "        #labels = np.load(labels_filepath, allow_pickle=True)[\"arr_0\"]\n",
    "        labels = np.asarray(sparse.load_npz(labels_filepath).todense()).ravel()\n",
    "        \n",
    "        # Truncate or pad to max length\n",
    "        #padded_token_ids = token_ids[:50] + [0] * (self.max_len - length)\n",
    "        return padded_token_ids, length, label\n",
    "\n",
    "    def collate_fn(self, batch_data):\n",
    "        padded_token_ids, lengths, labels = list(zip(*batch_data))\n",
    "        return (\n",
    "            torch.LongTensor(padded_token_ids).view(-1, self.max_len),\n",
    "            #torch.FloatTensor(lengths).view(-1, 1),\n",
    "            torch.FloatTensor(labels).view(-1, 1),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\"\"\"\n",
    "\n",
    "class DeepAveragingBinaryClassificationLModule(BinaryClassificationLModule):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def get_model(self) -> nn.Module:\n",
    "        return DeepAveragingNetworksModel(\n",
    "            #vocab=self.hparams.vocab,\n",
    "            vocab_size=self.hparams.train_batch_size,\n",
    "            word_embedding_size=self.hparams.word_embedding_size,\n",
    "            hidden_size=self.hparams.hidden_size,\n",
    "            num_intermediate_layers=self.hparams.num_intermediate_layers,\n",
    "            dropout_rate=self.hparams.dropout_rate,\n",
    "            use_glove=self.hparams.use_glove)\n",
    "\n",
    "    def batch2input(self, batch):\n",
    "        return {'input_ids': batch[0], 'lengths': 512}\n",
    "\n",
    "    def batch2labels(self, batch):\n",
    "        return batch[1].squeeze()\n",
    "\n",
    "    def get_dataloader(self, split, batch_size, shuffle=False) -> DataLoader:\n",
    "        data_dir = Path(self.hparams.data_dir)\n",
    "        features_filepath = data_dir.joinpath(\n",
    "            f\"{split}_{self.hparams.feature_name}_features.npz\")\n",
    "        labels_filepath = data_dir.joinpath(split + \"_labels.npz\")\n",
    "        features = sparse.load_npz(features_filepath).todense()\n",
    "        print('features shape:',features.shape)\n",
    "        #labels = np.load(labels_filepath, allow_pickle=True)[\"arr_0\"]\n",
    "        labels = np.asarray(sparse.load_npz(labels_filepath).todense()).ravel()\n",
    "        print('labels shape:',labels.shape)\n",
    "        dataset = torch.utils.data.TensorDataset(\n",
    "            torch.from_numpy(features).int(),\n",
    "            torch.from_numpy(labels).float())\n",
    "\n",
    "        logger.info(f\"Loading {split} data and labels from {labels_filepath}\")\n",
    "        data_loader = DataLoader(dataset=dataset,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=shuffle,\n",
    "                                 num_workers=self.hparams.num_workers\n",
    "                                 #,collate_fn=dataset.collate_fn\n",
    "                                 )\n",
    "\n",
    "        return data_loader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.hparams.optimizer == 'sgd':\n",
    "            optimizer = torch.optim.SGD(self.model.parameters(),\n",
    "                                        lr=self.hparams.learning_rate)\n",
    "        elif self.hparams.optimizer == 'adam':\n",
    "            optimizer = torch.optim.Adam(self.model.parameters(),\n",
    "                                         lr=self.hparams.learning_rate)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        # Hw-TODO: Add more optimizers and experiment with at least 2\n",
    "        #          optimizers other than vanilla SGD.\n",
    "        #          You can configure which optimizer to use by modifying\n",
    "        #          args_str or args passted to the function generic_train.\n",
    "        return optimizer\n",
    "\n",
    "    @classmethod\n",
    "    def add_model_specific_args(cls, parser: ArgumentParser) -> ArgumentParser:\n",
    "        parser = super().add_model_specific_args(parser)\n",
    "\n",
    "        # Required arguments\n",
    "        parser.add_argument('--num_intermediate_layers',\n",
    "                            type=int,\n",
    "                            help=\"number of intermediate layers\")\n",
    "        # Optional arguments\n",
    "        parser.add_argument('--dropout_rate',\n",
    "                            default=0.5,\n",
    "                            type=float,\n",
    "                            help=\"Dropout rate\")\n",
    "        parser.add_argument('--word_embedding_size',\n",
    "                            default=300,\n",
    "                            type=int,\n",
    "                            help=\"Size of word embeddings\")\n",
    "        parser.add_argument('--hidden_size',\n",
    "                            default=300,\n",
    "                            type=int,\n",
    "                            help=\"Size of hidden layer\")\n",
    "        parser.add_argument('--use_glove',\n",
    "                            action=\"store_true\",\n",
    "                            help=\"Whether to run predictions on the test set.\")\n",
    "        parser.add_argument('--task',\n",
    "                            default='danbinarycls',\n",
    "                            type=str,\n",
    "                            help=\"Name of the task.\")\n",
    "        parser.add_argument('--feature_name',\n",
    "                            default=None,\n",
    "                            type=str,\n",
    "                            required=True,\n",
    "                            help=\"Name of the feature\")\n",
    "        return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed arguments: Namespace(vocab_filename=None, optimizer='sgd', learning_rate=0.001, max_epochs=2, train_batch_size=32, eval_batch_size=32, seed=42, do_train=True, do_predict=True, data_dir='data', output_dir='output/dan', gpus=1, num_workers=8, num_intermediate_layers=1, dropout_rate=0.5, word_embedding_size=300, hidden_size=300, use_glove=False, task='danbinarycls', feature_name='roberta_readmit')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                       | Params\n",
      "--------------------------------------------------------\n",
      "0 | model    | DeepAveragingNetworksModel | 100 K \n",
      "1 | accuracy | Accuracy                   | 0     \n",
      "--------------------------------------------------------\n",
      "100 K     Trainable params\n",
      "0         Non-trainable params\n",
      "100 K     Total params\n",
      "0.401     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3921d4ae70864d6c988a53ebfd13db8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 15:27:24 - INFO - __main__ - Loading dev data and labels from data/dev_labels.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (58328, 512)\n",
      "labels shape: (58328,)\n",
      "input ids shape: torch.Size([32, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [78,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb Cell 12'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb#ch0000014vscode-remote?line=23'>24</a>\u001b[0m Path(args\u001b[39m.\u001b[39moutput_dir)\u001b[39m.\u001b[39mmkdir(parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb#ch0000014vscode-remote?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mParsed arguments: \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb#ch0000014vscode-remote?line=27'>28</a>\u001b[0m training_outout \u001b[39m=\u001b[39m generic_train(args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb#ch0000014vscode-remote?line=28'>29</a>\u001b[0m                                 model_class\u001b[39m=\u001b[39;49mDeepAveragingBinaryClassificationLModule)\n",
      "\u001b[1;32m/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb Cell 4'\u001b[0m in \u001b[0;36mgeneric_train\u001b[0;34m(args, model_class)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb#ch0000004vscode-remote?line=206'>207</a>\u001b[0m output_dict \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtrainer\u001b[39m\u001b[39m'\u001b[39m: trainer, \u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m: model}\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb#ch0000004vscode-remote?line=208'>209</a>\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mdo_train:\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb#ch0000004vscode-remote?line=209'>210</a>\u001b[0m     trainer\u001b[39m.\u001b[39;49mfit(model\u001b[39m=\u001b[39;49mmodel)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb#ch0000004vscode-remote?line=210'>211</a>\u001b[0m     \u001b[39m# Track model performance under differnt hparams settings in \"Hparams\" of TensorBoard\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb#ch0000004vscode-remote?line=211'>212</a>\u001b[0m     tensorboard_logger\u001b[39m.\u001b[39mlog_hyperparams(\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb#ch0000004vscode-remote?line=212'>213</a>\u001b[0m         params\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mhparams,\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb#ch0000004vscode-remote?line=213'>214</a>\u001b[0m         metrics\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mhp_metric\u001b[39m\u001b[39m'\u001b[39m: checkpoint_callback\u001b[39m.\u001b[39mbest_model_score\u001b[39m.\u001b[39mitem()})\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:740\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=734'>735</a>\u001b[0m     rank_zero_deprecation(\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=735'>736</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=736'>737</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m Use `trainer.fit(train_dataloaders)` instead. HINT: added \u001b[39m\u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=737'>738</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=738'>739</a>\u001b[0m     train_dataloaders \u001b[39m=\u001b[39m train_dataloader\n\u001b[0;32m--> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=739'>740</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=740'>741</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=741'>742</a>\u001b[0m )\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:685\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=674'>675</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=675'>676</a>\u001b[0m \u001b[39mError handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=676'>677</a>\u001b[0m \u001b[39mas all errors should funnel through them\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=681'>682</a>\u001b[0m \u001b[39m    **kwargs: keyword arguments to be passed to `trainer_fn`\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=682'>683</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=683'>684</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=684'>685</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=685'>686</a>\u001b[0m \u001b[39m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=686'>687</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:777\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=774'>775</a>\u001b[0m \u001b[39m# TODO: ckpt_path only in v1.7\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=775'>776</a>\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m--> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=776'>777</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=778'>779</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=779'>780</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1199\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1195'>1196</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1197'>1198</a>\u001b[0m \u001b[39m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1198'>1199</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch()\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1200'>1201</a>\u001b[0m \u001b[39m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1201'>1202</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_dispatch()\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1279\u001b[0m, in \u001b[0;36mTrainer._dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1276'>1277</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_type_plugin\u001b[39m.\u001b[39mstart_predicting(\u001b[39mself\u001b[39m)\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1277'>1278</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1278'>1279</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_type_plugin\u001b[39m.\u001b[39;49mstart_training(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py:202\u001b[0m, in \u001b[0;36mTrainingTypePlugin.start_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py?line=199'>200</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart_training\u001b[39m(\u001b[39mself\u001b[39m, trainer: \u001b[39m\"\u001b[39m\u001b[39mpl.Trainer\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py?line=200'>201</a>\u001b[0m     \u001b[39m# double dispatch to initiate the training loop\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py?line=201'>202</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_results \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mrun_stage()\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1289\u001b[0m, in \u001b[0;36mTrainer.run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1286'>1287</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1287'>1288</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1288'>1289</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1311\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1307'>1308</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_global_zero \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_bar_callback \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1308'>1309</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_bar_callback\u001b[39m.\u001b[39mdisable()\n\u001b[0;32m-> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1310'>1311</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module)\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1312'>1313</a>\u001b[0m \u001b[39m# enable train mode\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1313'>1314</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1375\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1372'>1373</a>\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1373'>1374</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m-> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1374'>1375</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1376'>1377</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_hook(\u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py?line=1378'>1379</a>\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=142'>143</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=143'>144</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=144'>145</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=145'>146</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=146'>147</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:110\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=104'>105</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_fetcher \u001b[39m=\u001b[39m dataloader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mget_profiled_dataloader(\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=105'>106</a>\u001b[0m     dataloader, dataloader_idx\u001b[39m=\u001b[39mdataloader_idx\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=106'>107</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=107'>108</a>\u001b[0m dl_max_batches \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_batches[dataloader_idx]\n\u001b[0;32m--> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=109'>110</a>\u001b[0m dl_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(dataloader, dataloader_idx, dl_max_batches, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_dataloaders)\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=111'>112</a>\u001b[0m \u001b[39m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py?line=112'>113</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs\u001b[39m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=142'>143</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=143'>144</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=144'>145</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=145'>146</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/base.py?line=146'>147</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:122\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dataloader_idx, dl_max_batches, num_dataloaders)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=119'>120</a>\u001b[0m \u001b[39m# lightning module methods\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=120'>121</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mevaluation_step_and_end\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=121'>122</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(batch, batch_idx, dataloader_idx)\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=122'>123</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step_end(output)\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=124'>125</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:217\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=214'>215</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=215'>216</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=216'>217</a>\u001b[0m         output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mvalidation_step(step_kwargs)\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py?line=218'>219</a>\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py:236\u001b[0m, in \u001b[0;36mAccelerator.validation_step\u001b[0;34m(self, step_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=230'>231</a>\u001b[0m \u001b[39m\"\"\"The actual validation step.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=231'>232</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=232'>233</a>\u001b[0m \u001b[39mSee :meth:`~pytorch_lightning.core.lightning.LightningModule.validation_step` for more details\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=233'>234</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=234'>235</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[0;32m--> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py?line=235'>236</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_type_plugin\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49mstep_kwargs\u001b[39m.\u001b[39;49mvalues())\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py:219\u001b[0m, in \u001b[0;36mTrainingTypePlugin.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py?line=217'>218</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidation_step\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py?line=218'>219</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb Cell 4'\u001b[0m in \u001b[0;36mBinaryClassificationLModule.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb#ch0000004vscode-remote?line=43'>44</a>\u001b[0m loss \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mbinary_cross_entropy(probs, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb#ch0000004vscode-remote?line=45'>46</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, loss)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/npodpx/class/nlp/n2c2-track2-nlp-uchicago/pytorch_pred.ipynb#ch0000004vscode-remote?line=46'>47</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccuracy(probs, labels\u001b[39m.\u001b[39;49mint()))\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/torchmetrics/metric.py:205\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/metric.py?line=198'>199</a>\u001b[0m     \u001b[39mraise\u001b[39;00m TorchMetricsUserError(\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/metric.py?line=199'>200</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe Metric shouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be synced when performing ``update``. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/metric.py?line=200'>201</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mHINT: Did you forget to call ``unsync`` ?.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/metric.py?line=201'>202</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/metric.py?line=203'>204</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/metric.py?line=204'>205</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/metric.py?line=206'>207</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_on_step:\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/metric.py?line=207'>208</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_sync \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdist_sync_on_step\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/torchmetrics/metric.py:263\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/metric.py?line=260'>261</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_computed \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/metric.py?line=261'>262</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_called \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/metric.py?line=262'>263</a>\u001b[0m \u001b[39mreturn\u001b[39;00m update(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/torchmetrics/classification/accuracy.py:228\u001b[0m, in \u001b[0;36mAccuracy.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/classification/accuracy.py?line=218'>219</a>\u001b[0m \u001b[39m\"\"\"Update state with predictions and targets. See\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/classification/accuracy.py?line=219'>220</a>\u001b[0m \u001b[39m:ref:`references/modules:input types` for more information on input\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/classification/accuracy.py?line=220'>221</a>\u001b[0m \u001b[39mtypes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/classification/accuracy.py?line=224'>225</a>\u001b[0m \u001b[39m    target: Ground truth labels\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/classification/accuracy.py?line=225'>226</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/classification/accuracy.py?line=226'>227</a>\u001b[0m \u001b[39m\"\"\" returns the mode of the data (binary, multi label, multi class, multi-dim multi class) \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/classification/accuracy.py?line=227'>228</a>\u001b[0m mode \u001b[39m=\u001b[39m _mode(preds, target, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthreshold, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtop_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_classes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmulticlass)\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/classification/accuracy.py?line=229'>230</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/classification/accuracy.py?line=230'>231</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m=\u001b[39m mode\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py:58\u001b[0m, in \u001b[0;36m_mode\u001b[0;34m(preds, target, threshold, top_k, num_classes, multiclass)\u001b[0m\n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py?line=28'>29</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_mode\u001b[39m(\n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py?line=29'>30</a>\u001b[0m     preds: Tensor,\n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py?line=30'>31</a>\u001b[0m     target: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py?line=34'>35</a>\u001b[0m     multiclass: Optional[\u001b[39mbool\u001b[39m],\n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py?line=35'>36</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataType:\n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py?line=36'>37</a>\u001b[0m     \u001b[39m\"\"\"Finds the mode of the input tensors.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py?line=37'>38</a>\u001b[0m \n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py?line=38'>39</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py?line=54'>55</a>\u001b[0m \u001b[39m        <DataType.MULTICLASS: 'multi-class'>\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py?line=55'>56</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py?line=57'>58</a>\u001b[0m     mode \u001b[39m=\u001b[39m _check_classification_inputs(\n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py?line=58'>59</a>\u001b[0m         preds, target, threshold\u001b[39m=\u001b[39;49mthreshold, top_k\u001b[39m=\u001b[39;49mtop_k, num_classes\u001b[39m=\u001b[39;49mnum_classes, multiclass\u001b[39m=\u001b[39;49mmulticlass\n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py?line=59'>60</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py?line=60'>61</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m mode\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/torchmetrics/utilities/checks.py:251\u001b[0m, in \u001b[0;36m_check_classification_inputs\u001b[0;34m(preds, target, threshold, num_classes, multiclass, top_k)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/utilities/checks.py?line=197'>198</a>\u001b[0m \u001b[39m\"\"\"Performs error checking on inputs for classification.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/utilities/checks.py?line=198'>199</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/utilities/checks.py?line=199'>200</a>\u001b[0m \u001b[39mThis ensures that preds and target take one of the shape/type combinations that are\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/utilities/checks.py?line=246'>247</a>\u001b[0m \u001b[39m        'multi-dim multi-class'\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/utilities/checks.py?line=247'>248</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/utilities/checks.py?line=249'>250</a>\u001b[0m \u001b[39m# Basic validation (that does not need case/type information)\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/utilities/checks.py?line=250'>251</a>\u001b[0m _basic_input_validation(preds, target, threshold, multiclass)\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/utilities/checks.py?line=252'>253</a>\u001b[0m \u001b[39m# Check that shape/types fall into one of the cases\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/utilities/checks.py?line=253'>254</a>\u001b[0m case, implied_classes \u001b[39m=\u001b[39m _check_shape_and_type_consistency(preds, target)\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/torchmetrics/utilities/checks.py:34\u001b[0m, in \u001b[0;36m_basic_input_validation\u001b[0;34m(preds, target, threshold, multiclass)\u001b[0m\n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/utilities/checks.py?line=31'>32</a>\u001b[0m \u001b[39mif\u001b[39;00m target\u001b[39m.\u001b[39mis_floating_point():\n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/utilities/checks.py?line=32'>33</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe `target` has to be an integer tensor.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/utilities/checks.py?line=33'>34</a>\u001b[0m \u001b[39mif\u001b[39;00m target\u001b[39m.\u001b[39mmin() \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/utilities/checks.py?line=34'>35</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe `target` has to be a non-negative tensor.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///home/npodpx/venv/lib/python3.9/site-packages/torchmetrics/utilities/checks.py?line=36'>37</a>\u001b[0m preds_float \u001b[39m=\u001b[39m preds\u001b[39m.\u001b[39mis_floating_point()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "                    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load hyperparameters\n",
    "parser = ArgumentParser()\n",
    "parser = DeepAveragingBinaryClassificationLModule.add_model_specific_args(parser)\n",
    "\n",
    "# NOTE: You should replace --optimizer <optimizer> with the name of the optimizer\n",
    "# with which you are experimenting with, and the same goes for word_embedding_size.\n",
    "# You can also configure other options listed in the method of add_model_specific_args of\n",
    "# the pytorch-lightning module `DeepAveragingBinaryClassificationLModule`.\n",
    "args_str = (\"--max_epochs 2 \"\n",
    "            \"--optimizer sgd --num_intermediate_layers 1 --feature_name roberta_readmit \"\n",
    "            \"--output_dir output/dan  --do_train --do_predict \")\n",
    "args = parser.parse_args(args_str.split())\n",
    "\n",
    "# If output_dir not provided, a folder is generated\n",
    "if args.output_dir is None:\n",
    "    args.output_dir = str(\n",
    "        Path('output').joinpath(\n",
    "            f\"{args.task}_{datetime.now().strftime('%Y%m%d-%H%M%S')}\"))\n",
    "Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Parsed arguments: {args}\")\n",
    "\n",
    "training_outout = generic_train(args=args,\n",
    "                                model_class=DeepAveragingBinaryClassificationLModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40f6b8985ae3d3af9736205d555f7ff87522357a9f5bdb6e88eda9160976b228"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
